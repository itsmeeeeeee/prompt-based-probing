{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ER5p4Vtsq9go5-7Ly-35GIc8RXKFGR3v","timestamp":1749669985438}],"collapsed_sections":["nqMK_r1AZO55"],"mount_file_id":"1ER5p4Vtsq9go5-7Ly-35GIc8RXKFGR3v","authorship_tag":"ABX9TyPPatgMIMAX8hbCQ6OE2R2z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import json\n","from pathlib import Path\n","from openai import OpenAI\n"],"metadata":{"id":"pIKPqkNxqlFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eEjGIp5fXsPE","executionInfo":{"status":"ok","timestamp":1750881503337,"user_tz":-120,"elapsed":17329,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"e1ab8663-1e58-4159-9511-53a0ea12594d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Templates übersetzen"],"metadata":{"id":"zMSYLutZqeod"}},{"cell_type":"code","source":["\n","client = OpenAI(api_key=\"\")\n","\n","INPUT_DIR = Path(\"/content/drive/MyDrive/master_thesis/data/factual_data/few_shots_final_1/permutation_0\")\n","OUTPUT_DIR = Path(\"/content/drive/MyDrive/master_thesis/data/multilingual_data/factual/tepmplates_test\")\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"hWo4tYCxqlJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Zielsprachen\n","TARGET_LANGS = {\n","    \"de\": \"German\",\n","    \"fr\": \"French\",\n","    \"it\": \"Italian\",\n","    \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",\n","    \"es\": \"Spanish\",\n","    \"th\": \"Thai\",\n","}\n","\n","# Übersetzungsfunktion mit gpt-4o\n","def translate_templates_with_gpt(templates, target_language):\n","    prompt = (\n","        f\"Translate the following English prompt templates into {target_language}. \"\n","        f\"Only return a JSON list of translated strings.\\n\\n\"\n","        f\"{json.dumps(templates, ensure_ascii=False, indent=2)}\"\n","    )\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o\",\n","        messages=[\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        temperature=0.2\n","    )\n","\n","    try:\n","        translated = json.loads(response.choices[0].message.content.strip())\n","        if isinstance(translated, list):\n","            return translated\n","    except Exception as e:\n","        print(f\"Fehler beim Parsen der GPT-Antwort: {e}\")\n","    return [\"\"] * len(templates)\n","\n","# Nur *_0shot.json-Dateien verarbeiten\n","for file in INPUT_DIR.glob(\"*_0shot.json\"):\n","    with open(file, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    english_templates = data.get(\"prompt_templates\", [])\n","    if not english_templates:\n","        print(f\"Keine prompt_templates in {file.name}\")\n","        continue\n","\n","    # Jede Sprache mit GPT übersetzen\n","    for lang_code, lang_name in TARGET_LANGS.items():\n","        print(f\"Übersetze {file.name} nach {lang_name}...\")\n","        translations = translate_templates_with_gpt(english_templates, lang_name)\n","        data[f\"prompt_templates_{lang_code}\"] = translations\n","\n","    # Speichern\n","    output_path = OUTPUT_DIR / file.name\n","    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"Gespeichert: {output_path.name}\")"],"metadata":{"id":"jEtrn5Y8qdd_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##linguistic data"],"metadata":{"id":"JQBtlSqjV2fo"}},{"cell_type":"markdown","source":["### antonym"],"metadata":{"id":"nqMK_r1AZO55"}},{"cell_type":"code","source":["import json\n","import time\n","import re\n","from pathlib import Path\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","\"\"\"\n","verarbeitet nur adjective_antonym.json\n","neuer Prompt erzwingt echte Adjektive, 1 Token, Klein­schreibung\n","\"\"\"\n","\n","API_KEY = \"\"\n","\n","INPUT_FILE  = Path(\"/content/drive/MyDrive/master_thesis/data/linguistic_data/zero_shot_linguistic/zero_shot_best_template/adjective_antonym.json\")\n","OUTPUT_FILE = Path(\"/content/drive/MyDrive/master_thesis/data/multilingual_data/linguistic/gpt_linguistic_final/adjective_antonym.json\")\n","OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n","\n","LANGS = {\n","    \"de\": \"German\", \"fr\": \"French\", \"it\": \"Italian\", \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",  \"es\": \"Spanish\", \"th\": \"Thai\"\n","}\n","\n","REL_PROMPT = {\n","    \"adj_antonym\": (\n","        # Kontext\n","        \"You are a professional linguist specialising in {lang}. \"\n","        \"Translate the **English adjective pair** “{w1} → {w2}” into {lang}. \"\n","        # Format\n","        \"Return **exactly two words**, lowercase, comma-separated, no extra text. \"\n","        # Regeln\n","        \"• Both outputs **must be adjectives in positive/base form** (no nouns, no verbs). \"\n","        \"• Provide **one token per word** – no spaces, hyphens or clitics. \"\n","        \"• Preserve all mandatory diacritics for {lang}. \"\n","        \"• If no direct one-word adjective exists, choose the best single-word approximation; \"\n","        \"do **not** fall back to verbs or nouns.\"\n","    )\n","}\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","\n","def _clean(txt: str) -> str:\n","    return re.sub(r'^\\W+|\\W+$', \"\", txt.strip())\n","\n","def _first_token(txt: str) -> str:\n","    return re.split(r\"[\\s,;→]\", txt)[0]\n","\n","def translate_word(word: str, lc: str, retries: int = 3) -> str:\n","    if not word:\n","        return \"\"\n","    prompt = (\n","        f\"Translate the word '{word}' into {LANGS[lc]} and output only the translation, \"\n","        \"no extra words, no quotes.\"\n","    )\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            return _first_token(_clean(r.choices[0].message.content))\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return word\n","\n","def translate_pair(w1: str, w2: str, rel: str, lc: str, retries: int = 3):\n","    prompt = REL_PROMPT[rel].format(w1=w1, w2=w2, lang=LANGS[lc])\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            parts = [p.strip() for p in r.choices[0].message.content.split(\",\") if p.strip()]\n","            if len(parts) == 2:\n","                return _first_token(_clean(parts[0])), _first_token(_clean(parts[1]))\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return translate_word(w1, lc), translate_word(w2, lc)\n","\n","data = json.loads(INPUT_FILE.read_text(\"utf-8\"))\n","\n","new_samples = []\n","for s in tqdm(data.get(\"samples\", []), desc=\"Samples\"):\n","    subj_en, obj_en = s[\"subject\"], s[\"object\"]\n","    entry = {\"subject\": subj_en, \"object\": obj_en}\n","\n","    for lc in LANGS:\n","        subj_tr, obj_tr = translate_pair(subj_en, obj_en, \"adj_antonym\", lc)\n","        entry[f\"subject_{lc}\"] = subj_tr\n","        entry[f\"object_{lc}\"]  = obj_tr\n","\n","    new_samples.append(entry)\n","\n","data[\"samples\"] = new_samples\n","\n","OUTPUT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","print(\"\\n adjective_antonym.json erfolgreich aktualisiert.\")\n"],"metadata":{"id":"jJw9yfcOXQj5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###comparativ"],"metadata":{"id":"hAfDiF_SZRtp"}},{"cell_type":"code","source":["import json\n","import time\n","import re\n","from pathlib import Path\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","\"\"\"\n","\n","• verarbeitet nur adjective_comparative.json\n","• neuer Prompt lässt 1- oder 2-Wort-Komparative zu\n","\"\"\"\n","\n","API_KEY = \"\"\n","\n","INPUT_FILE  = Path(\"/content/drive/MyDrive/master_thesis/data/linguistic_data/zero_shot_linguistic/zero_shot_best_template/adjective_comparative.json\")\n","OUTPUT_FILE = Path(\"/content/drive/MyDrive/master_thesis/data/multilingual_data/linguistic/gpt_linguistic_final/adjective_comparative.json\")\n","OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n","\n","LANGS = {\n","    \"de\": \"German\", \"fr\": \"French\", \"it\": \"Italian\", \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",  \"es\": \"Spanish\", \"th\": \"Thai\"\n","}\n","\n","REL_PROMPT = {\n","    \"adj_comparative\": (\n","        # Kontext\n","        \"You are a professional linguist specialising in {lang}. \"\n","        \"Translate the **English adjective pair** “{w1} → {w2}” into {lang}. \"\n","        # Format\n","        \"Return exactly two items, comma-separated, no extra text: \"\n","        \"1) the base adjective, 2) the comparative expression. \"\n","        # Regeln\n","        \"• Each item may contain one **or two** words (e.g. “plus grand”, “más grande”). \"\n","        \"• Both items must be adjectives; do not output nouns or verbs. \"\n","        \"• Preserve all diacritics and write in lowercase unless {lang} orthography requires otherwise. \"\n","        \"• Do not add intensifiers like 'very'; no articles or extra words.\"\n","    )\n","}\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","def _clean(txt: str) -> str:\n","    return re.sub(r'^\\W+|\\W+$', \"\", txt.strip())\n","\n","def _first_token(txt: str) -> str:\n","    \"\"\"Erstes Token vor Whitespace/Komma/→ (Bindestrich bleibt erhalten).\"\"\"\n","    return re.split(r\"[\\s,;→]\", txt)[0]\n","\n","def translate_word(word: str, lc: str, retries: int = 3) -> str:\n","    if not word:\n","        return \"\"\n","    prompt = (\n","        f\"Translate the word '{word}' into {LANGS[lc]} and output only the translation, \"\n","        \"no extra words, no quotes.\"\n","    )\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            return _first_token(_clean(r.choices[0].message.content))\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return word\n","\n","def translate_pair(w1: str, w2: str, rel: str, lc: str, retries: int = 3):\n","    prompt = REL_PROMPT[rel].format(w1=w1, w2=w2, lang=LANGS[lc])\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            parts = [p.strip() for p in r.choices[0].message.content.split(\",\") if p.strip()]\n","            if len(parts) == 2:\n","                if rel == \"adj_comparative\":\n","                    return _clean(parts[0]), _clean(parts[1])\n","\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return translate_word(w1, lc), translate_word(w2, lc)\n","\n","data = json.loads(INPUT_FILE.read_text(\"utf-8\"))\n","\n","# Prompt-Templates wie im Original in alle Sprachen übertragen\n","data[\"prompt_templates\"] = [\n","    {**{\"en\": tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\")},\n","     **{lc: translate_word(tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\"), lc)\n","        for lc in LANGS}}\n","    for tpl in data.get(\"prompt_templates\", [])\n","]\n","\n","new_samples = []\n","for s in tqdm(data.get(\"samples\", []), desc=\"Samples\"):\n","    subj_en, obj_en = s[\"subject\"], s[\"object\"]\n","    entry = {\"subject\": subj_en, \"object\": obj_en}\n","\n","    for lc in LANGS:\n","        subj_tr, obj_tr = translate_pair(subj_en, obj_en, \"adj_comparative\", lc)\n","        entry[f\"subject_{lc}\"] = subj_tr\n","        entry[f\"object_{lc}\"]  = obj_tr\n","\n","    new_samples.append(entry)\n","\n","data[\"samples\"] = new_samples\n","OUTPUT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","print(\"\\n adjective_comparative.json erfolgreich aktualisiert.\")\n"],"metadata":{"id":"8i7nwIPyaXcx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###superlativ"],"metadata":{"id":"YXAworhIcilc"}},{"cell_type":"code","source":["import json\n","import time\n","import re\n","from pathlib import Path\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","\"\"\"\n","verarbeitet ausschließlich adjective_superlative.json\n","Prompt deckt alle Sprachen ab, mit deutschem Spezialfall\n","superlativ darf 1 oder 2 Wörter sein (z. B. „more dull“)\n","\"\"\"\n","\n","API_KEY = \"\"\n","\n","INPUT_FILE  = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/linguistic_data/\"\n","    \"zero_shot_linguistic/zero_shot_best_template/adjective_superlative.json\"\n",")\n","OUTPUT_FILE = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/multilingual_data/\"\n","    \"linguistic/gpt_linguistic_final/adjective_superlative.json\"\n",")\n","OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n","\n","LANGS = {\n","    \"de\": \"German\", \"fr\": \"French\", \"it\": \"Italian\", \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",  \"es\": \"Spanish\", \"th\": \"Thai\"\n","}\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","def build_super_prompt(w1: str, w2: str, lc: str) -> str:\n","    \"\"\"Erzeuge den Superlativ-Prompt, inkl. DE-Spezialregel.\"\"\"\n","    common = (\n","        \"You are a professional linguist specialising in {lang}. \"\n","        \"Translate the **English adjective pair** “{w1} → {w2}” into {lang}. \"\n","        \"Return exactly two items, comma-separated, no extra text: \"\n","        \"1) the base adjective, 2) its superlative expression. \"\n","        \"Rules: \"\n","        \"• The superlative may contain one **or two** words \"\n","        \"(e.g. “plus grand”, “más grande”). \"\n","        \"• Both items must be adjectives – no nouns or verbs. \"\n","        \"• Preserve all diacritics and write in lowercase unless \"\n","        \"{lang} orthography requires capitals. \"\n","    )\n","    if lc == \"de\":\n","        extra = (\n","            \"• Allowed superlatives: attributive (stamm + -ste/-sten) **or** \"\n","            \"prädikativ (“am” + stamm + -sten). \"\n","            \"• Do not include articles like “der/die/das”. \"\n","            \"• Use the same word stem; no other adjectives.\"\n","        )\n","    else:\n","        extra = (\n","            \"• Omit definite articles (le, la, el, il, o …). \"\n","            \"• Use the correct irregular form when it exists \"\n","            \"(e.g. ‘best’ = ‘meilleur’ in French).\"\n","        )\n","    return (common + extra).format(w1=w1, w2=w2, lang=LANGS[lc])\n","\n","def _clean(txt: str) -> str:\n","    return re.sub(r'^\\W+|\\W+$', \"\", txt.strip())\n","\n","def _first_token(txt: str) -> str:\n","    return re.split(r\"[\\s,;→]\", txt)[0]\n","\n","def translate_word(word: str, lc: str, retries: int = 3) -> str:\n","    if not word:\n","        return \"\"\n","    prompt = (\n","        f\"Translate the word '{word}' into {LANGS[lc]} and output only the translation, \"\n","        \"no extra words, no quotes.\"\n","    )\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            return _first_token(_clean(r.choices[0].message.content))\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return word\n","\n","def translate_pair(w1: str, w2: str, lc: str, retries: int = 3):\n","    prompt = build_super_prompt(w1, w2, lc)\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            parts = [p.strip() for p in r.choices[0].message.content.split(\",\") if p.strip()]\n","            if len(parts) == 2:\n","                return _clean(parts[0]), _clean(parts[1])\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return translate_word(w1, lc), translate_word(w2, lc)\n","\n","data = json.loads(INPUT_FILE.read_text(\"utf-8\"))\n","\n","# Prompt-Templates wie im Ursprungscode in alle Sprachen übersetzen\n","data[\"prompt_templates\"] = [\n","    {**{\"en\": tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\")},\n","     **{lc: translate_word(tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\"), lc)\n","        for lc in LANGS}}\n","    for tpl in data.get(\"prompt_templates\", [])\n","]\n","\n","for s in tqdm(data[\"samples\"], desc=\"Samples\"):\n","    base_en, sup_en = s[\"subject\"], s[\"object\"]\n","    for lc in LANGS:\n","        s[f\"subject_{lc}\"], s[f\"object_{lc}\"] = translate_pair(base_en, sup_en, lc)\n","\n","OUTPUT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","print(\" adjective_superlative.json erfolgreich aktualisiert.\")\n"],"metadata":{"id":"DQU1DhA4aXgK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###verb past tense"],"metadata":{"id":"Dbci2-ApeLKt"}},{"cell_type":"code","source":["\"\"\"\n","übersetzt ALLE Samples in 7 Sprachen, ohne englische Fallbacks\n","nutzt neue Prompt-Regeln für de/hi/th\n","\"\"\"\n","\n","import json, re, time\n","from pathlib import Path\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","API_KEY = \"\"\n","BASE    = \"/content/drive/MyDrive/master_thesis/data\"\n","\n","IN_F  = Path(f\"{BASE}/linguistic_data/zero_shot_linguistic/zero_shot_best_template/verb_past_tense.json\")\n","OUT_F = Path(f\"{BASE}/multilingual_data/linguistic/gpt_linguistic_final/verb_past_tense.json\")\n","OUT_F.parent.mkdir(parents=True, exist_ok=True)\n","\n","LANGS = {\n","    \"de\": \"German\", \"fr\": \"French\", \"it\": \"Italian\", \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",  \"es\": \"Spanish\", \"th\": \"Thai\"\n","}\n","SEP_PREFIXES = (\"ab\",\"an\",\"auf\",\"aus\",\"ein\",\"mit\",\"nach\",\"vor\",\n","                \"weg\",\"zu\",\"zurück\",\"zusammen\",\"los\",\"weiter\",\"fest\")\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","def build_prompt(inf, past, lc):\n","    lang = LANGS[lc]\n","    base = (\n","        \"You are a professional linguist specialising in {lang}. \"\n","        \"Translate the English verb pair “{inf} (infinitive) → {past} (simple past)” into {lang}. \"\n","        \"Return exactly ONE line in the form:\\n<infinitive>|<past>\\n\"\n","        \"No extra text. Use lowercase, keep diacritics, no particles or auxiliaries.\"\n","    )\n","    extra = {\n","        \"de\": \" For separable verbs include the prefix in the past form, joined with a hyphen (gab-auf).\",\n","        \"hi\": \" Hindi infinitive ends with “न” (e.g. पूछन); past masc. singular is bare root (e.g. पूछ).\",\n","        \"th\": \" Thai verbs do not inflect; output “<verb>|<verb แล้ว>”, with a space before แล้ว.\"\n","    }.get(lc, \"\")\n","    return base.format(lang=lang, inf=inf, past=past) + extra\n","\n","def post_process(inf, past, lc):\n","    inf, past = inf.lower(), past.lower()\n","    if lc == \"de\":\n","        pref = next((p for p in SEP_PREFIXES if inf.startswith(p)), \"\")\n","        if pref and \"-\" not in past:\n","            past = f\"{past}-{pref}\"\n","    elif lc == \"hi\":\n","        inf  = re.sub(\"ना?$\", \"न\", inf)\n","        past = re.sub(\"ा?$\",  \"\", past)\n","    elif lc == \"th\":\n","        past = inf + \" แล้ว\"\n","    return inf, past\n","\n","def translate_pair(inf_en, past_en, lc, retries=4):\n","    prompt = build_prompt(inf_en, past_en, lc)\n","    for attempt in range(retries):\n","        try:\n","            rsp = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                temperature=0,\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                max_tokens=25\n","            )\n","            raw = rsp.choices[0].message.content.strip()\n","            if \"|\" in raw:\n","                parts = [p.strip() for p in raw.split(\"|\", 1)]\n","            else:\n","                parts = re.split(r\"[,\\n]\", raw, maxsplit=1)\n","            if len(parts) == 2 and all(parts):\n","                return post_process(*parts, lc)\n","        except Exception:\n","            time.sleep(2 * (attempt + 1))\n","    raise RuntimeError(f\"GPT-Übersetzung fehlgeschlagen für {inf_en} → {lc}\")\n","\n","data = json.loads(IN_F.read_text(\"utf-8\"))\n","\n","for s in tqdm(data[\"samples\"], desc=\"Übersetze Samples\"):\n","    inf_en, past_en = s[\"subject\"], s[\"object\"]\n","    for lc in LANGS:\n","        inf_tr, past_tr = translate_pair(inf_en, past_en, lc)\n","        s[f\"subject_{lc}\"] = inf_tr\n","        s[f\"object_{lc}\"]  = past_tr\n","\n","OUT_F.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","print(\" Alle Samples übersetzt & gespeichert →\", OUT_F)\n"],"metadata":{"id":"ROS6ekZVAu8e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### word last letter/first letter"],"metadata":{"id":"Ybyd1Hiye4RN"}},{"cell_type":"code","source":["\n","\"\"\"\n","Word-Letter-Relationen (first / last)\n","übersetzt pro Sprache nur das Subjekt\n"," Objekt wird aus der Übersetzung gebildet:\n","  – first-letter.json\n","  – last-letter.json\n","\"\"\"\n","\n","import json\n","import re\n","import time\n","from pathlib import Path\n","\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","API_KEY = \"\"\n","BASE    = \"/content/drive/MyDrive/master_thesis/data\"\n","\n","IN_DIR  = Path(f\"{BASE}/linguistic_data/zero_shot_linguistic/zero_shot_best_template\")\n","OUT_DIR = Path(f\"{BASE}/multilingual_data/linguistic/gpt_linguistic_final\")\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","FILES = {\n","    \"word_first_letter.json\": \"first\",\n","    \"word_last_letter.json\":  \"last\"\n","}\n","\n","LANGS = {\n","    \"de\": \"German\", \"fr\": \"French\", \"it\": \"Italian\", \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",  \"es\": \"Spanish\", \"th\": \"Thai\"\n","}\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","def clean(txt: str) -> str:\n","    return re.sub(r\"^\\W+|\\W+$\", \"\", txt.strip())\n","\n","def first_char(word: str) -> str:\n","    word = clean(word)\n","    return word[0] if word else \"\"\n","\n","def last_char(word: str) -> str:\n","    word = clean(word)\n","    return word[-1] if word else \"\"\n","\n","def translate_word(word: str, lc: str, retries: int = 3) -> str:\n","    prompt = (\n","        f\"Translate the word '{word}' into {LANGS[lc]} and output only the translation, \"\n","        \"no extra words, no quotes.\"\n","    )\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            return clean(r.choices[0].message.content).split()[0]  # erstes Token\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return word\n","\n","for fname, mode in FILES.items():\n","    src = IN_DIR  / fname\n","    dst = OUT_DIR / fname\n","    if not src.exists():\n","        print(f\"{fname} fehlt – übersprungen.\")\n","        continue\n","\n","    data = json.loads(src.read_text(\"utf-8\"))\n","\n","    data[\"prompt_templates\"] = [\n","        {**{\"en\": tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\")},\n","         **{lc: translate_word(tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\"), lc)\n","            for lc in LANGS}}\n","        for tpl in data.get(\"prompt_templates\", [])\n","    ]\n","\n","    for samp in tqdm(data[\"samples\"], desc=f\"{fname}\"):\n","        subj_en = samp[\"subject\"]\n","\n","        # Englisch unverändert\n","        if mode == \"first\":\n","            samp[\"object\"] = first_char(subj_en)\n","        else:\n","            samp[\"object\"] = last_char(subj_en)\n","\n","        # Alle Zielsprachen\n","        for lc in LANGS:\n","            subj_tr = translate_word(subj_en, lc)\n","            samp[f\"subject_{lc}\"] = subj_tr.upper()\n","\n","            if mode == \"first\":\n","                samp[f\"object_{lc}\"] = first_char(subj_tr).upper()\n","            else:\n","                samp[f\"object_{lc}\"] = last_char(subj_tr).upper()\n","\n","    dst.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","    print(f\" {fname} fertig → {dst}\")\n","\n","print(\"\\n  First-/Last-Letter-Dateien erfolgreich aktualisiert.\")\n","\n"],"metadata":{"id":"drz_RQ4of65C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["hi/thia"],"metadata":{"id":"1dE8zoMfqaZo"}},{"cell_type":"code","source":["\"\"\"\n","Word‑Letter‑Relationen (first / last)\n","übersetzt NUR THAI und HINDI (alle anderen Sprachen werden ignoriert)\n","Objekt wird aus der Übersetzung gebildet\n","LANGS enthält jetzt ausschließlich \"hi\" und \"th\".\n","Extraktion des sichtbaren Buchstabens nutzt Unicode‑Kategorie \"L\".\n","\n"," – first-letter.json\n","  – last-letter.json\n","\n","\"\"\"\n","\n","import json\n","import re\n","import time\n","import unicodedata\n","from pathlib import Path\n","\n","from openai import OpenAI\n","from tqdm import tqdm\n","\n","API_KEY = \"\"\n","BASE    = \"/content/drive/MyDrive/master_thesis/data\"\n","\n","IN_DIR  = Path(f\"{BASE}/linguistic_data/zero_shot_linguistic/zero_shot_best_template\")\n","OUT_DIR = Path(f\"{BASE}/multilingual_data/linguistic/gpt_linguistic_final_last_letter_hi_thai\")\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","FILES = {\n","    \"word_first_letter.json\": \"first\",\n","    \"word_last_letter.json\":  \"last\"\n","}\n","\n","# Nur Thai & Hindi\n","LANGS = {\"hi\": \"Hindi\", \"th\": \"Thai\"}\n","\n","client = OpenAI(api_key=API_KEY)\n","\n","\n","def clean(txt: str) -> str:\n","    \"\"\"Trimmt führende/trailende Nicht‑Buchstaben‑Zeichen.\"\"\"\n","    return re.sub(r\"^\\W+|\\W+$\", \"\", txt.strip())\n","\n","\n","def visible_letters(word: str):\n","    \"\"\"Alle sichtbaren Buchstaben (Unicode‑Kategorie 'L*').\"\"\"\n","    return [c for c in clean(word) if unicodedata.category(c).startswith(\"L\")]\n","\n","\n","def first_visible_letter(word: str) -> str:\n","    letters = visible_letters(word)\n","    return letters[0] if letters else \"\"\n","\n","\n","def last_visible_letter(word: str) -> str:\n","    letters = visible_letters(word)\n","    return letters[-1] if letters else \"\"\n","\n","\n","def translate_word(word: str, lc: str, retries: int = 3) -> str:\n","    prompt = (\n","        f\"Translate the word '{word}' into {LANGS[lc]} and output only the translation, \"\n","        \"no extra words, no quotes.\"\n","    )\n","    for a in range(retries):\n","        try:\n","            r = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0\n","            )\n","            return clean(r.choices[0].message.content).split()[0]\n","        except Exception:\n","            time.sleep(2 * (a + 1))\n","    return word\n","\n","for fname, mode in FILES.items():\n","    src = IN_DIR  / fname\n","    dst = OUT_DIR / fname\n","    if not src.exists():\n","        print(f\"  {fname} fehlt – übersprungen.\")\n","        continue\n","\n","    data = json.loads(src.read_text(\"utf-8\"))\n","\n","    # Prompt‑Templates übersetzen (nur hi + th)\n","    data[\"prompt_templates\"] = [\n","        {**{\"en\": tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\")},\n","         **{lc: translate_word(tpl if isinstance(tpl, str) else tpl.get(\"en\", \"\"), lc)\n","            for lc in LANGS}}\n","        for tpl in data.get(\"prompt_templates\", [])\n","    ]\n","\n","    for samp in tqdm(data[\"samples\"], desc=f\"{fname}\"):\n","        subj_en = samp[\"subject\"]\n","\n","        # Englisch‑basiertes Objekt (überschreibt oder ergänzt, egal)\n","        if mode == \"first\":\n","            samp[\"object\"] = subj_en[0]\n","        else:\n","            samp[\"object\"] = subj_en[-1]\n","\n","        # Nur Thai & Hindi\n","        for lc in LANGS:\n","            subj_tr = translate_word(subj_en, lc)\n","            samp[f\"subject_{lc}\"] = subj_tr.upper()\n","\n","            if mode == \"first\":\n","                samp[f\"object_{lc}\"] = first_visible_letter(subj_tr).upper()\n","            else:\n","                samp[f\"object_{lc}\"] = last_visible_letter(subj_tr).upper()\n","\n","    dst.write_text(json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\")\n","    print(f\" {fname} fertig → {dst}\")\n","\n","print(\"\\n  First-/Last-Letter‑Dateien (nur Thai & Hindi) erfolgreich aktualisiert.\")\n"],"metadata":{"id":"KcBPhBvrf68g"},"execution_count":null,"outputs":[]}]}