{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ER5p4Vtsq9go5-7Ly-35GIc8RXKFGR3v","timestamp":1749832941662}],"collapsed_sections":["38tShNRlWp5T","6LyZWCBeWp8o","LvXb-oSIzZ8u","ulatgggTYFUW"],"mount_file_id":"1ER5p4Vtsq9go5-7Ly-35GIc8RXKFGR3v","authorship_tag":"ABX9TyPJCnY2OxR4vU5aGLdLaM7W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eEjGIp5fXsPE","executionInfo":{"status":"ok","timestamp":1750756682833,"user_tz":-120,"elapsed":23595,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"40870164-438a-4579-8ebd-5edb51f1b50f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Wikidata ID (Entitäten ID mit API extrahieren)"],"metadata":{"id":"u28abaZlxLaY"}},{"cell_type":"code","source":["import json, pathlib, time, urllib.parse, requests\n","\n","\n","\n","\n","INPUT_FILE  = \"/content/drive/MyDrive/master_thesis/data/factual_data/zero_shot_factual/new_factual/superhero_person.json\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/zero_shot_factual/wikidata/superhero_person.json\"\n","LANG        = \"en\"\n","MAX_RETRY   = 3\n","\n","def wikidata_id(label: str, lang: str = LANG) -> str | None:\n","    \"\"\"Return the Wikidata Q‑ID whose label matches *label* exactly.\n","\n","    Behaviour:\n","        • Up to 7 search results are queried.\n","        • A case‑insensitive, trimmed exact‑label match is required.\n","        • If no exact match is found, **None** is returned so the caller can\n","          mark the value as \"N/A\".\n","    \"\"\"\n","    base = \"https://www.wikidata.org/w/api.php\"\n","    params = {\n","        \"action\": \"wbsearchentities\",\n","        \"search\": label,\n","        \"language\": lang,\n","        \"format\": \"json\",\n","\n","        \"type\": \"item\",\n","        \"limit\": 7,\n","        \"origin\": \"*\"\n","    }\n","    url = f\"{base}?{urllib.parse.urlencode(params)}\"\n","\n","    for attempt in range(1, MAX_RETRY + 1):\n","        try:\n","            hits = requests.get(url, timeout=30).json().get(\"search\", [])\n","            if hits:\n","                canonical = label.strip().lower()\n","                for h in hits:\n","                    if h.get(\"label\", \"\").strip().lower() == canonical:\n","                        return h[\"id\"]\n","                return None\n","        except Exception as e:\n","            if attempt == MAX_RETRY:\n","                print(f\"  {label}: {e}\")\n","            time.sleep(1.5 * attempt)\n","    return None\n","\n","\n","data = json.loads(pathlib.Path(INPUT_FILE).read_text(encoding=\"utf-8\"))\n","\n","for sample in data[\"samples\"]:\n","    s_label = sample[\"subject\"]\n","    o_label = sample[\"object\"]\n","\n","    sample[\"subject_id\"] = wikidata_id(s_label) or \"N/A\"\n","    sample[\"object_id\"]  = wikidata_id(o_label) or \"N/A\"\n","\n","    time.sleep(5)\n","\n","pathlib.Path(OUTPUT_FILE).write_text(\n","    json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\"\n",")\n","print(f\"✅  Datei mit IDs geschrieben: {OUTPUT_FILE}\")"],"metadata":{"id":"k-Z5ikTfGfUJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Shots ID extrahieren"],"metadata":{"id":"sV2gHZvaxZQj"}},{"cell_type":"code","source":["import json, pathlib, time, urllib.parse, requests\n","\n","\n","\n","INPUT_FILE  = \"/content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/few_shots/factual_en.json\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/few_shots/wikidata_id_factual_en.json\"\n","LANG        = \"en\"\n","MAX_RETRY   = 3\n","\n","\n","def wikidata_id_shots(label: str, lang: str = LANG) -> str | None:\n","    \"\"\"Return the Wikidata Q‑ID whose label matches *label* exactly.\n","\n","    Behaviour:\n","        • Up to 10 search results are queried.\n","        • A case‑insensitive, trimmed exact‑label match is required.\n","        • If no exact match is found, **None** is returned so the caller can\n","          mark the value as \"N/A\".  (We intentionally avoid the previous\n","          fallback of using the first hit, to maximise precision.)\n","    \"\"\"\n","    base = \"https://www.wikidata.org/w/api.php\"\n","    params = {\n","        \"action\": \"wbsearchentities\",\n","        \"search\": label,\n","        \"language\": lang,\n","        \"format\": \"json\",\n","        \"type\": \"item\",\n","        \"limit\": 7,\n","        \"origin\": \"*\"\n","    }\n","    url = f\"{base}?{urllib.parse.urlencode(params)}\"\n","\n","    for attempt in range(1, MAX_RETRY + 1):\n","        try:\n","            hits = requests.get(url, timeout=30).json().get(\"search\", [])\n","            if hits:\n","                canonical = label.strip().lower()\n","                for h in hits:\n","                    if h.get(\"label\", \"\").strip().lower() == canonical:\n","                        return h[\"id\"]\n","                # Fallback: no exact label match\n","                return None\n","        except Exception as e:\n","            if attempt == MAX_RETRY:\n","                print(f\"{label}: {e}\")\n","            time.sleep(1.5 * attempt)\n","    return None\n","\n","\n","data = json.loads(pathlib.Path(INPUT_FILE).read_text(encoding=\"utf-8\"))\n","\n","for sample in data:\n","\n","  for el in data[sample]:\n","\n","    s_label = el[0]\n","    o_label = el[1]\n","\n","    el.append({\"subject_id\":wikidata_id(s_label) or \"N/A\"})\n","    el.append({\"object_id\":wikidata_id(o_label) or \"N/A\"})\n","\n","    time.sleep(5)\n","\n","\n","pathlib.Path(OUTPUT_FILE).write_text(\n","    json.dumps(data, ensure_ascii=False, indent=2), \"utf-8\"\n",")\n","print(f\" Datei mit IDs geschrieben: {OUTPUT_FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uvNBZn9IpGs","executionInfo":{"status":"ok","timestamp":1750326911890,"user_tz":-120,"elapsed":1325167,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"3d07d341-6c2e-4474-d04e-7dd6d86e515a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅  Datei mit IDs geschrieben: /content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/few_shots/wikidata_id_factual_en.json\n"]}]},{"cell_type":"markdown","source":["## Shots (Examples) multilingualer Wikidata Übersetzung (factual)"],"metadata":{"id":"38tShNRlWp5T"}},{"cell_type":"code","source":["\"\"\"Wikidata‑Label‑Exporter – Multilinguale Version\n","------------------------------------------------\n","Dieses Skript liest ein Few‑Shot‑JSON im Format der Masterarbeit ein und\n","schreibt pro Zielsprache eine neue Datei, in der Subjekt‑ und Objekt‑Labels\n","nach den folgenden Regeln erscheinen:\n","\n","1. FULL_TRANSLATE  →  immer Subjekt **und** Objekt in allen 7 Sprachen\n","2. PARTIAL_TRANSLATE\n","   • Für Hindi (hi) & Thai (th):  immer beide Labels übersetzen\n","   • Für de, fr, it, pt, es:      Regeln laut PARTIAL_TRANSLATE‑Dict\n","       – True    → immer übersetzen\n","       – False  → immer englisches Fallback\n","       – \"maybe\"→ nur übersetzen, wenn Wikidata ein Label in der Zielsprache hat\n","3. NO_TRANSLATE    →  nur für hi & th übersetzen; sonst Englisch behalten\n","\n","Falls kein Q‑ID‑Eintrag existiert oder Wikidata kein Label liefert, wird ein\n","Leerstring (\"\") ausgegeben.\n","\"\"\"\n","\n","from __future__ import annotations\n","\n","import json\n","import requests\n","from pathlib import Path\n","from time import sleep\n","from typing import Dict, List, Tuple, Set\n","\n","\n","INPUT_FILE = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/few_shots/wikidata_id_factual_en.json\"\n",")\n","OUTPUT_TEMPLATE = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/wikidata_translation\"\n",")\n","LANGS: List[str] = [\"de\", \"fr\", \"it\", \"pt\", \"hi\", \"es\", \"th\"]\n","\n","MAX_TIMEOUT = 15\n","API_PAUSE_S = 3\n","\n","#  Übersetzungsregeln per Relation\n","FULL_TRANSLATE: List[str] = [\n","    \"city_in_country\",      # Stadt | Land\n","    \"country_capital_city\", # Land  | Hauptstadt\n","    \"country_currency\",     # Land  | Währung\n","    \"country_language\",     # Land  | Amtssprache\n","    \"country_largest_city\", # Land  | Größte Stadt\n","    \"food_from_country\",    # Gericht| Land\n","    \"landmark_in_country\",  # Landmarke| Land\n","    \"landmark_on_continent\",# Landmarke| Kontinent\n","]\n","\n","PARTIAL_TRANSLATE: Dict[str, Tuple[str | bool, str | bool]] = {\n","    \"company_hq\":                     (False, True),\n","    \"person_occupation\":              (False, True),\n","    \"person_plays_instrument\":        (False, True),\n","    \"person_plays_position_in_sport\": (False, True),\n","    \"person_plays_pro_sport\":         (False, True),\n","    \"person_university\":              (False, True),\n","    \"star_constellation\":             (False, True),\n","}\n","\n","NO_TRANSLATE: List[str] = [\n","    \"company_ceo\",\n","    \"person_band_lead_singer\",\n","    \"person_father\",\n","    \"person_mother\",\n","    \"pokemon_evolutions\",\n","    \"presidents_birth_year\",\n","    \"presidents_election_year\",\n","    \"product_by_company\",\n","    \"superhero_archnemesis\",\n","    \"superhero_person\",\n","]\n","\n","LATIN_LANGS: Set[str] = {\"de\", \"fr\", \"it\", \"pt\", \"es\"}\n","ASIAN_LANGS: Set[str] = {\"hi\", \"th\"}\n","\n","with INPUT_FILE.open(encoding=\"utf-8\") as fh:\n","    data_in: Dict[str, List[List]] = json.load(fh)\n","\n","all_qids: Set[str] = set()\n","for samples in data_in.values():\n","    for s in samples:\n","        all_qids.add(s[2].get(\"subject_id\", \"\"))\n","        all_qids.add(s[3].get(\"object_id\", \"\"))\n","\n","all_qids = {qid for qid in all_qids if qid.startswith(\"Q\")}\n","print(f\" Sammle Labels für {len(all_qids)} eindeutige Q‑IDs …\")\n","\n","#  Alle Labels von Wikidata holen (ein Call je Q‑ID)\n","ALL_LANGS = LANGS + [\"en\"]\n","label_cache: Dict[str, Dict[str, str]] = {\n","    qid: {lang: \"\" for lang in ALL_LANGS} for qid in all_qids\n","}\n","\n","for qid in all_qids:\n","    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n","    try:\n","        resp = requests.get(url, timeout=MAX_TIMEOUT)\n","        resp.raise_for_status()\n","        labels = resp.json()[\"entities\"][qid][\"labels\"]\n","        for lang in ALL_LANGS:\n","            if lang in labels:\n","                label_cache[qid][lang] = labels[lang][\"value\"]\n","    except Exception as exc:\n","        print(f\"  {qid}: {exc}\")\n","    sleep(API_PAUSE_S)\n","\n","print(\"Alle Wikidata‑Aufrufe abgeschlossen.\")\n","\n","#Entscheidungslogik, ob ein Label übersetzt werden soll\n","\n","def should_translate(rel: str, role: str, lang: str, qid: str) -> bool:\n","    \"\"\"Gibt True zurück, wenn das Lokalisieren des Labels für diese\n","    Relation/Position/Zielsprache erwünscht ist.\"\"\"\n","    #  FULL\n","    if rel in FULL_TRANSLATE:\n","        return True\n","\n","    # PARTIAL\n","    if rel in PARTIAL_TRANSLATE:\n","        subj_rule, obj_rule = PARTIAL_TRANSLATE[rel]\n","        rule = subj_rule if role == \"subject\" else obj_rule\n","\n","        # Hindi & Thai → immer lokalisieren\n","        if lang in ASIAN_LANGS:\n","            return True\n","\n","        # Lateinische Sprachen → Flag auswerten\n","        if rule is True:\n","            return True\n","        if rule is False:\n","            return False\n","        if rule == \"maybe\":\n","            # nur übersetzen, wenn Wikidata ein Label hat\n","            return bool(label_cache.get(qid, {}).get(lang))\n","        return False\n","\n","    # NO_TRANSLATE\n","    if rel in NO_TRANSLATE:\n","        return lang in ASIAN_LANGS  # only hi/th\n","\n","    return True\n","\n","\n","def get_label(qid: str, lang: str) -> str:\n","    \"\"\"Hilfsfunktion: Holt Label aus Cache oder gibt Leerstring zurück.\"\"\"\n","    return label_cache.get(qid, {}).get(lang, \"\")\n","\n","for lang in LANGS:\n","    data_out: Dict[str, List[List[str]]] = {}\n","\n","    for rel, samples in data_in.items():\n","        translated_samples: List[List[str]] = []\n","\n","        for s in samples:\n","            subj_q = s[2].get(\"subject_id\", \"\")\n","            obj_q = s[3].get(\"object_id\", \"\")\n","\n","            # Subjekt‑Label\n","            if subj_q:\n","                subj_lbl = (\n","                    get_label(subj_q, lang)\n","                    if should_translate(rel, \"subject\", lang, subj_q)\n","                    else get_label(subj_q, \"en\")\n","                )\n","            else:\n","                subj_lbl = \"\"\n","\n","            # Objekt‑Label\n","            if obj_q:\n","                obj_lbl = (\n","                    get_label(obj_q, lang)\n","                    if should_translate(rel, \"object\", lang, obj_q)\n","                    else get_label(obj_q, \"en\")\n","                )\n","            else:\n","                obj_lbl = \"\"\n","\n","            translated_samples.append([subj_lbl, obj_lbl])\n","\n","        data_out[rel] = translated_samples\n","\n","    out_path = OUTPUT_TEMPLATE.with_name(f\"{OUTPUT_TEMPLATE.name}_{lang}.json\")\n","    out_path.parent.mkdir(parents=True, exist_ok=True)\n","    with out_path.open(\"w\", encoding=\"utf-8\") as fh:\n","        json.dump(data_out, fh, ensure_ascii=False, indent=2)\n","\n","    print(f\" {lang.upper()}‑Datei geschrieben → {out_path}\")\n","\n","print(\"\\n Fertig!  Alle sieben Sprachdateien liegen im Zielordner.\")\n"],"metadata":{"id":"slCjhYvdVVEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Übersetzung mit wikidata id"],"metadata":{"id":"6LyZWCBeWp8o"}},{"cell_type":"code","source":["\n","\n","\"\"\"\"\n","FULL_TRANSLATE = [\n","    \"city_in_country\",\n","    \"country_capital_city\",\n","    \"country_currency\",\n","    \"country_language\",\n","    \"country_largest_city\",\n","]\n","\"\"\"\n","import json\n","import requests\n","from time import sleep\n","\n","# Eingabedatei und Zielsprachen\n","INPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata/country_currency_with_id.json\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata_translation/country_currency_wikidata_translated.json\"\n","\n","import json\n","import pathlib\n","import requests\n","from time import sleep\n","\n","\n","TARGET_LANGS = {\n","    \"de\": \"German\",\n","    \"fr\": \"French\",\n","    \"it\": \"Italian\",\n","    \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",\n","    \"es\": \"Spanish\",\n","    \"th\": \"Thai\",\n","}\n","\n","API_PAUSE_S = 3\n","MAX_TIMEOUT = 15\n","\n","_label_cache: dict[str, dict[str, str]] = {}\n","\n","def get_wikidata_full_translation(qid: str, langs: list[str]) -> dict[str, str]:\n","    \"\"\"\n","    Liefert ein Dict {lang: label} für die gewünschten Sprachen.\n","    Ergebnisse werden in einem einfachen In-Memory-Cache gehalten,\n","    um Mehrfachaufrufe für dieselbe Q-ID zu sparen.\n","    \"\"\"\n","    if qid in _label_cache:                 # Cache-Hit\n","        return {lang: _label_cache[qid].get(lang, \"\")\n","                for lang in langs}\n","\n","    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n","\n","    try:\n","        resp = requests.get(url, timeout=MAX_TIMEOUT)\n","        resp.raise_for_status()\n","        data   = resp.json()\n","        labels = data[\"entities\"][qid][\"labels\"]\n","        result = {lang: labels[lang][\"value\"] for lang in langs if lang in labels}\n","        _label_cache[qid] = result\n","        return result\n","    except Exception as e:\n","        print(f\"Error fetching {qid}: {e}\")\n","        return {}\n","\n","with open(INPUT_FILE, encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","for sample in data[\"samples\"]:\n","    for role in (\"subject\", \"object\"):\n","        qid = sample.get(f\"{role}_id\")\n","\n","        if qid and qid.startswith(\"Q\"):\n","            translations = get_wikidata_full_translation(qid, list(TARGET_LANGS.keys()))\n","        else:\n","            translations = {lang: \"\" for lang in TARGET_LANGS}\n","\n","        for lang in TARGET_LANGS:\n","            sample[f\"{role}_{lang}\"] = translations.get(lang, \"\")\n","\n","    sleep(API_PAUSE_S)\n","\n","with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","try:\n","    import pandas as pd\n","    df = pd.DataFrame(data[\"samples\"])\n","    print(df.head())\n","except ImportError:\n","    pass\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpNDNvMq03RN","executionInfo":{"status":"ok","timestamp":1750187394801,"user_tz":-120,"elapsed":105374,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"c43c850f-d8f4-4f84-9f4a-1e1ff889e979"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["❌ Error fetching Q10321999: 404 Client Error: Not Found for url: https://www.wikidata.org/wiki/Special:EntityData/Q10321999.json\n","          subject  object subject_id  object_id              subject_de  \\\n","0   United States  Dollar        Q30      Q4917      Vereinigte Staaten   \n","1  United Kingdom   Pound       Q145     Q25224  Vereinigtes Königreich   \n","2           Japan   Q8146        Q17  Q37195199                   Japan   \n","3          Canada  Dollar        Q16     Q14083                  Kanada   \n","4       Australia  Dollar       Q408     Q14083              Australien   \n","\n","    subject_fr             subject_it      subject_pt             subject_hi  \\\n","0   États-Unis  Stati Uniti d'America  Estados Unidos  संयुक्त राज्य अमेरिका   \n","1  Royaume-Uni            Regno Unito     Reino Unido        यूनाइटेड किंगडम   \n","2        Japon               Giappone           Japão                  जापान   \n","3       Canada                 Canada          Canadá                  कनाडा   \n","4    Australie              Australia       Austrália            ऑस्ट्रेलिया   \n","\n","       subject_es        subject_th       object_de         object_fr  \\\n","0  Estados Unidos      สหรัฐอเมริกา       US-Dollar  dollar américain   \n","1     Reino Unido     สหราชอาณาจักร  Pfund Sterling    livre sterling   \n","2           Japón     ประเทศญี่ปุ่น             Yen               Yen   \n","3          Canadá      ประเทศแคนาดา   Dollarwährung            dollar   \n","4       Australia  ประเทศออสเตรเลีย   Dollarwährung            dollar   \n","\n","              object_it        object_pt         object_hi  \\\n","0  dollaro statunitense  dólar americano      अमेरिकी डॉलर   \n","1   sterlina britannica  libra esterlina  पाउण्ड स्टर्लिंग   \n","2                   Yen              Yen                     \n","3               dollaro            dólar             डाॅलर   \n","4               dollaro            dólar             डाॅलर   \n","\n","              object_es       object_th  \n","0  dólar estadounidense    ดอลลาร์สหรัฐ  \n","1       libra esterlina  ปอนด์สเตอร์ลิง  \n","2                   Yen                  \n","3                 dólar         ดอลลาร์  \n","4                 dólar         ดอลลาร์  \n"]}]},{"cell_type":"code","source":["import json\n","import requests\n","from time import sleep\n","\n","\n","\n","\n","INPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata/person_university_with_id.json\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata_translation/person_university_wikidata_translated.json\"\n","\n","TARGET_LANGS = {\n","    \"de\": \"German\",\n","    \"fr\": \"French\",\n","    \"it\": \"Italian\",\n","    \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",\n","    \"es\": \"Spanish\",\n","    \"th\": \"Thai\",\n","}\n","\n","API_PAUSE_S = 3\n","MAX_TIMEOUT = 15\n","\n","_label_cache: dict[str, dict[str, str]] = {}\n","\n","def get_wikidata_partial_translation(qid: str, langs: list[str]) -> dict[str, str]:\n","    if qid in _label_cache:\n","        return {lang: _label_cache[qid].get(lang, \"\") for lang in langs}\n","\n","    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n","    try:\n","        resp = requests.get(url, timeout=MAX_TIMEOUT)\n","        resp.raise_for_status()\n","        data = resp.json()\n","        labels = data[\"entities\"][qid][\"labels\"]\n","        result = {lang: labels[lang][\"value\"] for lang in langs if lang in labels}\n","        _label_cache[qid] = result\n","        return result\n","    except Exception as e:\n","        print(f\"❌ Error fetching {qid}: {e}\")\n","        return {}\n","\n","# JSON laden\n","with open(INPUT_FILE, encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","# Samples verarbeiten\n","for sample in data[\"samples\"]:\n","    for role in (\"subject\", \"object\"):\n","        qid = sample.get(f\"{role}_id\")\n","\n","        # Objekt wird in alle Sprachen übersetzt\n","        if role == \"object\":\n","            translations = get_wikidata_partial_translation(qid, list(TARGET_LANGS.keys())) if qid and qid.startswith(\"Q\") else {lang: \"\" for lang in TARGET_LANGS}\n","            for lang in TARGET_LANGS:\n","                sample[f\"{role}_{lang}\"] = translations.get(lang, \"\")\n","\n","        # Subjekt: nur hi und th übersetzen, sonst Englisch übernehmen\n","        elif role == \"subject\":\n","            translations = get_wikidata_partial_translation(qid, [\"hi\", \"th\"]) if qid and qid.startswith(\"Q\") else {lang: \"\" for lang in [\"hi\", \"th\"]}\n","            for lang in TARGET_LANGS:\n","                if lang in {\"hi\", \"th\"}:\n","                    sample[f\"{role}_{lang}\"] = translations.get(lang, \"\")\n","                else:\n","                    sample[f\"{role}_{lang}\"] = sample[\"subject\"]  # Englisch übernehmen\n","\n","    sleep(API_PAUSE_S)\n","\n","# JSON speichern\n","with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","# Vorschau\n","try:\n","    import pandas as pd\n","    df = pd.DataFrame(data[\"samples\"])\n","    print(df.head())\n","except ImportError:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axaRxWekdIbp","executionInfo":{"status":"ok","timestamp":1750196030064,"user_tz":-120,"elapsed":310782,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"7e7c8b70-bd35-49d4-a817-bfe7e64c5052"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           subject                      object subject_id object_id  \\\n","0   Michelle Obama        Princeton University     Q13133    Q21578   \n","1       Bill Gates          Harvard University      Q5284    Q13371   \n","2  Mark Zuckerberg          Harvard University     Q36215    Q13371   \n","3    Oprah Winfrey  Tennessee State University     Q55800  Q1782948   \n","4      Emma Watson            Brown University     Q39476    Q49114   \n","\n","        subject_de       subject_fr       subject_it       subject_pt  \\\n","0   Michelle Obama   Michelle Obama   Michelle Obama   Michelle Obama   \n","1       Bill Gates       Bill Gates       Bill Gates       Bill Gates   \n","2  Mark Zuckerberg  Mark Zuckerberg  Mark Zuckerberg  Mark Zuckerberg   \n","3    Oprah Winfrey    Oprah Winfrey    Oprah Winfrey    Oprah Winfrey   \n","4      Emma Watson      Emma Watson      Emma Watson      Emma Watson   \n","\n","         subject_hi       subject_es            subject_th  \\\n","0       मिशेल ओबामा   Michelle Obama        มิเชลล์ โอบามา   \n","1         बिल गेट्स       Bill Gates             บิล เกตส์   \n","2  मार्क ज़ुकेरबर्ग  Mark Zuckerberg  มาร์ก ซักเคอร์เบิร์ก   \n","3      ओपरा विनफ्रे    Oprah Winfrey      โอปราห์ วินฟรีย์   \n","4         एमा वॉटसन      Emma Watson         เอ็มมา วอตสัน   \n","\n","                    object_de                       object_fr  \\\n","0        Princeton University         université de Princeton   \n","1          Harvard University              université Harvard   \n","2          Harvard University              université Harvard   \n","3  Tennessee State University  université d'État du Tennessee   \n","4            Brown University                université Brown   \n","\n","                    object_it                   object_pt  \\\n","0     Università di Princeton   Universidade de Princeton   \n","1       Università di Harvard        Universidade Harvard   \n","2       Università di Harvard        Universidade Harvard   \n","3  Tennessee State University  Tennessee State University   \n","4            Università Brown          Universidade Brown   \n","\n","                object_hi                 object_es             object_th  \n","0  प्रिंसटन विश्वविद्यालय  Universidad de Princeton  มหาวิทยาลัยพรินซ์ตัน  \n","1  हार्वर्ड विश्वविद्यालय       Universidad Harvard  มหาวิทยาลัยฮาร์วาร์ด  \n","2  हार्वर्ड विश्वविद्यालय       Universidad Harvard  มหาวิทยาลัยฮาร์วาร์ด  \n","3                                                                          \n","4                                 Universidad Brown     มหาวิทยาลัยบราวน์  \n"]}]},{"cell_type":"code","source":["import json\n","import requests\n","from time import sleep\n","\n","# Eingabedatei und Zieldatei\n","INPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata/pokemon_evolutions_with_id.json\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata_translation/pokemon_evolutions_wikidata_translated.json\"\n","\n","TARGET_LANGS = {\n","    \"de\": \"German\",\n","    \"fr\": \"French\",\n","    \"it\": \"Italian\",\n","    \"pt\": \"Portuguese\",\n","    \"hi\": \"Hindi\",\n","    \"es\": \"Spanish\",\n","    \"th\": \"Thai\",\n","}\n","\n","API_PAUSE_S = 3\n","MAX_TIMEOUT = 15\n","\n","_label_cache: dict[str, dict[str, str]] = {}\n","\n","def get_wikidata_thai_hindi_translation(qid: str, langs: list[str]) -> dict[str, str]:\n","    if qid in _label_cache:\n","        return {lang: _label_cache[qid].get(lang, \"\") for lang in langs}\n","\n","    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n","    try:\n","        resp = requests.get(url, timeout=MAX_TIMEOUT)\n","        resp.raise_for_status()\n","        data = resp.json()\n","        labels = data[\"entities\"][qid][\"labels\"]\n","        result = {lang: labels[lang][\"value\"] for lang in langs if lang in labels}\n","        _label_cache[qid] = result\n","        return result\n","    except Exception as e:\n","        print(f\"❌ Error fetching {qid}: {e}\")\n","        return {}\n","\n","# JSON laden\n","with open(INPUT_FILE, encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","# Samples durchlaufen & Sprachen setzen\n","for sample in data[\"samples\"]:\n","    for role in (\"subject\", \"object\"):\n","        qid = sample.get(f\"{role}_id\")\n","\n","        # Nur für hi und th übersetzen\n","        langs_to_translate = [\"hi\", \"th\"]\n","        translations = get_wikidata_thai_hindi_translation(qid, langs_to_translate) if qid and qid.startswith(\"Q\") else {lang: \"\" for lang in langs_to_translate}\n","\n","        for lang in TARGET_LANGS:\n","            if lang in langs_to_translate:\n","                sample[f\"{role}_{lang}\"] = translations.get(lang, \"\")\n","            else:\n","                sample[f\"{role}_{lang}\"] = sample[role]  # englischer Originalwert\n","\n","    sleep(API_PAUSE_S)\n","\n","# Ergebnis speichern\n","with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","# Vorschau\n","try:\n","    import pandas as pd\n","    df = pd.DataFrame(data[\"samples\"])\n","    print(df.head())\n","except ImportError:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfzHB1ySwqi2","executionInfo":{"status":"ok","timestamp":1750202489100,"user_tz":-120,"elapsed":143421,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"c13ef592-aca6-4e2b-b05a-39c91545c798"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      subject      object subject_id object_id  subject_de  subject_fr  \\\n","0   Bulbasaur     Ivysaur    Q847571  Q1636903   Bulbasaur   Bulbasaur   \n","1  Charmander  Charmeleon   Q3178753  Q1637365  Charmander  Charmander   \n","2    Squirtle   Wartortle    Q845294  Q1752151    Squirtle    Squirtle   \n","3     Pikachu      Raichu      Q9351  Q1647331     Pikachu     Pikachu   \n","4      Oddish       Gloom   Q2002874  Q5571265      Oddish      Oddish   \n","\n","   subject_it  subject_pt subject_hi  subject_es   subject_th   object_de  \\\n","0   Bulbasaur   Bulbasaur              Bulbasaur  ฟุชิงิดาเนะ     Ivysaur   \n","1  Charmander  Charmander             Charmander   ฮิโตะคาเงะ  Charmeleon   \n","2    Squirtle    Squirtle               Squirtle    เซนิกาเมะ   Wartortle   \n","3     Pikachu     Pikachu     पिकाचु     Pikachu       พิคาชู      Raichu   \n","4      Oddish      Oddish                 Oddish                    Gloom   \n","\n","    object_fr   object_it   object_pt object_hi   object_es object_th  \n","0     Ivysaur     Ivysaur     Ivysaur               Ivysaur  ฟุชิกิโซ  \n","1  Charmeleon  Charmeleon  Charmeleon            Charmeleon   ลิซาโดะ  \n","2   Wartortle   Wartortle   Wartortle             Wartortle     คาเมล  \n","3      Raichu      Raichu      Raichu                Raichu      ไรชู  \n","4       Gloom       Gloom       Gloom                 Gloom            \n"]}]},{"cell_type":"markdown","source":["##test wikiid und entitäten"],"metadata":{"id":"LvXb-oSIzZ8u"}},{"cell_type":"code","source":["#Bengaluru\n","#Ministry of Foreign Affairs - Moscow"],"metadata":{"id":"ymzkgYude2w8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#testen nur die Entitäten oder id\n","\n","import requests, urllib.parse, json\n","term=\"Microsoft\"\n","#Bengaluru\n","\n","url = (\"https://www.wikidata.org/w/api.php?\"\n","       \"action=wbsearchentities&format=json&language=en&type=item&limit=10&\"\n","       f\"search={urllib.parse.quote(term)}\")\n","hits = requests.get(url).json()[\"search\"]\n","for h in hits:\n","\n","  descr = h.get(\"description\", \"\").lower()\n","  #if (\"contry\" in descr) or (\"currency\" in descr):\n","  print(h[\"id\"], \"→\", h[\"label\"], \"|\", descr)\n","    #o_label = sample[\"object\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uQz0DkG4zzd","executionInfo":{"status":"ok","timestamp":1750337644985,"user_tz":-120,"elapsed":214,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"0633d810-40c6-4067-8e2d-1ae38b2a06c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Q2283 → Microsoft | american multinational technology corporation\n","Q1406 → Microsoft Windows | family of computer operating systems developed by microsoft\n","Q135288 → Microsoft Store | digital distribution platform from microsoft\n","Q132020 → Xbox | video game console by microsoft\n","Q11215 → Windows 7 | personal computer operating system by microsoft that was released in 2009\n","Q11272 → Microsoft Excel | spreadsheet editor, part of microsoft 365\n","Q11230 → Windows Vista | personal computer operating system by microsoft that was released in 2007\n","Q5046 → Windows 8 | personal computer operating system by microsoft that was released in 2012\n","Q60683589 → Microsoft Academic Knowledge Graph | rdf representation of the microsoft academic graph\n","Q83370 → Windows 95 | personal computer operating system by microsoft\n"]}]},{"cell_type":"code","source":["import json, requests, urllib.parse, pathlib, time\n","INPUT_FILE = \"/content/drive/MyDrive/master_thesis/data/fewshot_examples/factual/few_shots/wikidata_id_factual_en.json\"\n","\n","data = json.loads(pathlib.Path(INPUT_FILE).read_text(encoding=\"utf-8\"))\n","\n","for sample in data[\"samples\"]:\n","    subject=sample[\"subject\"]\n","    object_=sample[\"object\"]\n","    s_label = sample[\"subject_id\"]\n","    o_label = sample[\"object_id\"]\n","    url = (\"https://www.wikidata.org/w/api.php?\"\n","       \"action=wbsearchentities&format=json&language=en&type=item&limit=1&\"\n","       f\"search={urllib.parse.quote(s_label)}\")\n","    hits = requests.get(url).json()[\"search\"]\n","    for h in hits:\n","\n","      descr = h.get(\"description\", \"\").lower()\n","      print(h[\"id\"], \"→\", h[\"label\"], \"|\", descr)\n","\n","\n","    url = (\"https://www.wikidata.org/w/api.php?\"\n","       \"action=wbsearchentities&format=json&language=en&type=item&limit=1&\"\n","       f\"search={urllib.parse.quote(o_label)}\")\n","    hits = requests.get(url).json()[\"search\"]\n","    for h in hits:\n","\n","      descr = h.get(\"description\", \"\").lower()\n","\n","\n","      print(h[\"id\"], \"→\", h[\"label\"], \"|\", descr)\n","\n","\n","    time.sleep(3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"ZT6-x3WY7enz","executionInfo":{"status":"error","timestamp":1750337237307,"user_tz":-120,"elapsed":200,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"e32cd061-4bbf-46ab-c531-166a21bf9710"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'samples'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-39-416232149.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mobject_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'samples'"]}]},{"cell_type":"markdown","source":["##übersetze liste"],"metadata":{"id":"ulatgggTYFUW"}},{"cell_type":"code","source":["# --------------------------------------------------------\n","# 1) Komplett übersetzen\n","# --------------------------------------------------------\n","FULL_TRANSLATE = [\n","    \"city_in_country\",\n","    \"country_capital_city\",\n","    \"country_currency\",\n","    \"country_language\",\n","    \"country_largest_city\",\n","    \"food_from_country\":\n","    \"landmark_in_country\":\n","    \"landmark_on_continent\":\n","]\n","# --------------------------------------------------------\n","# 2) Teilweise übersetzen\n","# --------------------------------------------------------\n","PARTIAL_TRANSLATE = {\n","    \"company_hq\":                     (False,  True),   # Firma | Stadt\n","    \"person_occupation\":              (False,  True),   # Person  | Beruf\n","    \"person_plays_instrument\":        (False,  True),   # Person  | Instrument\n","    \"person_plays_position_in_sport\": (False,  True),   # Person  | Position\n","    \"person_plays_pro_sport\":         (False,  True),   # Person  | Sportart\n","    \"person_university\":              (False, True), # Person  | Uni-Name\n","    \"star_constellation\":             (False, True), # Stern   | Sternbild\n","}\n","# --------------------------------------------------------\n","# 3) Unverändert\n","# --------------------------------------------------------\n","NO_TRANSLATE = [\n","    \"company_ceo\",\n","    \"person_band_lead_singer\",\n","    \"person_father\",\n","    \"person_mother\",\n","    \"pokemon_evolutions\",\n","    \"presidents_birth_year\",\n","    \"presidents_election_year\",\n","    \"product_by_company\",\n","    \"superhero_archnemesis\",\n","    \"superhero_person\",\n","]\n"],"metadata":{"id":"VlCpmr7aURbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tm3bpFNoeEXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##multilingualer- dataset"],"metadata":{"id":"tZi6_TZeeE-r"}},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"merge_multilingual_datasets.py\n","\n","Merge multilingual *template* JSONs with matching *translation-sample* JSONs.\n","\n","Directory layout\n","────────────────\n","1. **Templates** (25 files)\n","   /content/drive/MyDrive/master_thesis/data/multilingual_data/factual/tepmplates_test\n","   └─ e.g. ``city_in_country_0shot.json`` (keys: ``name``, ``prompt_templates``)\n","\n","2. **Samples**\n","   /content/drive/MyDrive/master_thesis/data/multilingual_data/factual/gpt_translate_thai_hindi_all\n","   └─ e.g. ``city_in_country_wikidata_translated.json`` (key: ``samples``)\n","\n","We match files after stripping well‑known suffixes:\n","* Template suffix ``_0shot``\n","* Sample suffix  ``_wikidata_translated``\n","\n","**Important change**\n","The merged output is now saved **without** the ``_0shot`` suffix, e.g.::\n","\n","    city_in_country.json\n","\n","All 25 merged JSONs are written to\n","/content/drive/MyDrive/master_thesis/data/multilingual_data/factual/multilingual_dataset/multilingual_gpt_thai_hindi\n","with structure::\n","\n","    {\n","      \"name\": \"...\",\n","      \"prompt_templates\": [...],\n","      \"samples\": [...]\n","    }\n","\"\"\"\n","\n","from __future__ import annotations\n","\n","import json\n","import sys\n","from pathlib import Path\n","from typing import Any, Dict\n","\n","# ---------- CONFIG ---------- #\n","TEMPLATES_DIR = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/multilingual_data/factual/tepmplates_test\"\n",")\n","SAMPLES_DIR = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/factual_data/wikidata_translation_samples\"\n",")\n","OUTPUT_DIR = Path(\n","    \"/content/drive/MyDrive/master_thesis/data/multilingual_data/factual/multilingual_dataset/multilingual_wikidata_translate\"\n",")\n","DEFAULT_ENCODING = \"utf-8\"\n","\n","SUFFIXES_TEMPLATE = [\"_0shot\"]\n","SUFFIXES_SAMPLE = [\"_wikidata_translated\"]\n","\n","# ---------- UTILITIES ---------- #\n","\n","def read_json(path: Path) -> Dict[str, Any]:\n","    with path.open(\"r\", encoding=DEFAULT_ENCODING) as fp:\n","        return json.load(fp)\n","\n","\n","def write_json(data: Dict[str, Any], path: Path) -> None:\n","    with path.open(\"w\", encoding=DEFAULT_ENCODING) as fp:\n","        json.dump(data, fp, ensure_ascii=False, indent=2)\n","\n","\n","def canonical_filename(name: str, *, is_template: bool) -> str:\n","    \"\"\"Return the canonical core name without suffixes and extension.\"\"\"\n","    if name.endswith(\".json\"):\n","        name = name[:-5]\n","    suffixes = SUFFIXES_TEMPLATE if is_template else SUFFIXES_SAMPLE\n","    for suf in suffixes:\n","        if name.endswith(suf):\n","            name = name[: -len(suf)]\n","            break\n","    return name\n","\n","# ---------- DISCOVER SAMPLE FILES ---------- #\n","\n","def build_sample_lookup(root: Path) -> Dict[str, Path]:\n","    \"\"\"Map canonical_key → sample_path (first occurrence wins).\"\"\"\n","    lookup: Dict[str, Path] = {}\n","    for path in root.rglob(\"*.json\"):\n","        try:\n","            data = read_json(path)\n","        except Exception:\n","            continue  # skip invalid JSON\n","        if \"samples\" not in data:\n","            continue  # not a sample file\n","        key = canonical_filename(path.name, is_template=False)\n","        lookup.setdefault(key, path)\n","    return lookup\n","\n","# ---------- MERGE ---------- #\n","\n","def merge() -> None:\n","    if not TEMPLATES_DIR.is_dir():\n","        sys.exit(f\"[FATAL] templates dir not found: {TEMPLATES_DIR}\")\n","    if not SAMPLES_DIR.is_dir():\n","        sys.exit(f\"[FATAL] samples dir not found: {SAMPLES_DIR}\")\n","\n","    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","    sample_lookup = build_sample_lookup(SAMPLES_DIR)\n","    print(f\"[INFO] Discovered {len(sample_lookup)} usable sample files\\n\")\n","\n","    processed = 0\n","    for tpl_path in sorted(TEMPLATES_DIR.glob(\"*.json\")):\n","        canonical_key = canonical_filename(tpl_path.name, is_template=True)\n","        sample_path = sample_lookup.get(canonical_key)\n","\n","        if sample_path is None:\n","            print(f\"[WARN] No sample for {tpl_path.name} (key '{canonical_key}')\")\n","            continue\n","\n","        try:\n","            tpl = read_json(tpl_path)\n","            smp = read_json(sample_path)\n","        except Exception as exc:\n","            print(f\"[ERROR] Read failure: {exc}\")\n","            continue\n","\n","        merged = {\n","            \"name\": tpl.get(\"name\"),\n","            \"prompt_templates\": tpl.get(\"prompt_templates\", []),\n","            \"samples\": smp.get(\"samples\", []),\n","        }\n","\n","        # ---- Save without the _0shot suffix ---- #\n","        out_filename = f\"{canonical_key}.json\"  # ensures suffix removed\n","        out_path = OUTPUT_DIR / out_filename\n","\n","        try:\n","            write_json(merged, out_path)\n","            processed += 1\n","            print(f\"[OK]\\t{out_path.relative_to(OUTPUT_DIR.parent.parent)}\")\n","        except Exception as exc:\n","            print(f\"[ERROR] Write failure: {exc}\")\n","\n","    print(f\"\\nFinished. {processed} files written to {OUTPUT_DIR}\\n\")\n","\n","\n","if __name__ == \"__main__\":\n","    merge()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzQYmIdngErn","executionInfo":{"status":"ok","timestamp":1750343873857,"user_tz":-120,"elapsed":1075,"user":{"displayName":"Aldi Halili","userId":"04451056983466283749"}},"outputId":"967a6590-7dcd-4cb0-aa82-4bf1c13f26f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Discovered 25 usable sample files\n","\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/city_in_country.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/company_ceo.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/company_hq.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/country_capital_city.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/country_currency.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/country_language.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/country_largest_city.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/food_from_country.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/landmark_in_country.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/landmark_on_continent.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_band_lead_singer.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_father.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_mother.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_occupation.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_plays_instrument.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_plays_position_in_sport.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_plays_pro_sport.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/person_university.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/pokemon_evolutions.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/presidents_birth_year.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/presidents_election_year.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/product_by_company.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/star_constellation.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/superhero_archnemesis.json\n","[OK]\tmultilingual_dataset/multilingual_wikidata_translate/superhero_person.json\n","\n","Finished. 25 files written to /content/drive/MyDrive/master_thesis/data/multilingual_data/factual/multilingual_dataset/multilingual_wikidata_translate\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"izfXPZOxlU-d"},"execution_count":null,"outputs":[]}]}